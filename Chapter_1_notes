	# 1. Introduction to Big Data 

	## What is BigData?  
	A collection of data that is too big to be handled by traditional data  management tools or data processing application.
	Eg. When Netflix recommend movies or shows to you that is BigData at work.  
	
	### 5 V’s in Big Data   
| ----------- | ----------- |
| Volume | data is getting bigger and bigger  |
	Variety	- different kinds of data is being generated(structured, semi, unstructured)  
	Velocity - velocity means the speed of something in a given direction, data is being generated at an alarming rate  
	Value - how can we mine the useful value from the data, we have to make sure the data generated makes sense and we can get insight from it  
	Veracity - veracity means the accuracy and correctness of data  
	
	### Big Data Analytics  
	Opportunities: faster and better decision making, cost reduction, next generation products, improved services or products  
	Eg. IBM Smart Meter Solution  
	IBM offers an integrated suite of products designed to enable IT to leverage big data in a variety ways that can contribute to the success of energy companies.
	Solution:  
		A) Data Warehousing  
		B) User Data Security  
		C) Data Mining  
		D) Data Analysis  
		E) Reporting  
	
	Problems: Storing huge datasets, processing data with complex structure, data is growing faster than that of disk read/write speed  
	
	
	
	**~~~  HADOOP as a SOLUTION  ~~~**  
	
	- What is Hadoop?  
	Hadoop is a framework that allows us to store and process large datasets in parallel and distributed fashion.  
	There are two parts of Hadoop: *HDFS* and *MapReduce*  
	
	**A) HDFS(Hadoop Distributed File System)**  
	HDFS creates a level of abstraction over the resources, from where we can see the whole HDFS as a single unit.  
	
	HDFS has two components>> NameNode and DataNode  
	
	NameNode: MainNode that contains metadata about the data stored  
	DataNode: Data is stored in here which are commodity hardware in the distributed environment  
	
	
	• Solving problem 1: Storing huge dataset
	
	
	• Solving Problem 2: Storing unstructured data
	
	
	
	B) MapReduce
	MapReduce allows parallel processing of the data stored in HDFS
	
	• Solving Problem 3: Processing data faster
	
	
	How it works?  
	If the Slaves were to send the data to the Master to process at once, network congestion would happen.  
	But if the Master send the processing logic to each Slaves to process locally and then only send the result back to Master, then time and resources can be saved.  
	
	
###What does a Big Data Engineer Do?  
	- Design, Develop, Construct, Install, Test&Maintain the complete infrastructure of data management and processing systems  
	- Build pipeline for data collection and storage, make the data consumable for Data Scientists and Data Analysts to drive insights  
	- Build data warehouses, systems should all be scalable, robust and fault tolerant  
	- Take care of the process of ETL(Extract, Transform and Load)  
	- Performance tuning  

###Responsibilities  
>> Data Ingestion: Acquire data from multiple sources and ingest them into data lake  
>> Data Transformation: Convert data from one format to another, or from one structure to another based on use-case  
>> Performance Optimization: Scalable and efficient system(optimize queries performance, denormalize partition and index data models, tools and concepts)  



	1. Big Data Frameworks  


	2. Real time processing frameworks - Apache Spark  

	5. NoSQL Databases - Cassandra(good for application with fast and random read and write), MongoDB(schema free DB, master/slave architecture), Apache Hbase(On top of HDFS)  
	
	6. Programming Languages - Python, R, Java  

	7. ETL/Data warehousing - data warehousing is used for analytics and reporting, Informatica, Talend(recomm to start with this if beginner), Microsoft SQL Server, QlikView   

	8. Operation Systems - Windows, Linux, Unix  

